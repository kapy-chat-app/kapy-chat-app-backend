/* eslint-disable @typescript-eslint/no-explicit-any */
// src/lib/services/gemini.service.ts - FIX INCOMPLETE RESPONSES

import { GoogleGenerativeAI } from "@google/generative-ai";

interface EmotionContext {
  recentEmotions: Array<{
    emotion: string;
    confidence: number;
    timestamp: Date;
  }>;
  dominantEmotion: string;
  emotionIntensity: number;
}

export class GeminiService {
  private genAI: GoogleGenerativeAI;
  private model: any;
  private cache: Map<string, { data: any; timestamp: number }> = new Map();
  private readonly CACHE_TTL = 5 * 60 * 1000;

  constructor() {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY is not set in environment variables");
    }

    this.genAI = new GoogleGenerativeAI(apiKey);
    const modelName = process.env.GEMINI_MODEL || "gemini-1.5-pro";

    this.model = this.genAI.getGenerativeModel({
      model: modelName,
    });

    console.log("ğŸ¤– Gemini AI Service initialized:", {
      model: modelName,
      apiKeyLength: apiKey.length,
      billing: "TIER 1 âœ…",
    });
  }

  private getCached<T>(key: string): T | null {
    const cached = this.cache.get(key);
    if (!cached) return null;
    const isExpired = Date.now() - cached.timestamp > this.CACHE_TTL;
    if (isExpired) {
      this.cache.delete(key);
      return null;
    }
    console.log("âœ… Cache HIT:", key);
    return cached.data as T;
  }

  private setCache<T>(key: string, data: T): void {
    this.cache.set(key, { data, timestamp: Date.now() });
  }

  private async retryWithBackoff<T>(
    fn: () => Promise<T>,
    maxRetries: number = 3,
    initialDelay: number = 1000
  ): Promise<T> {
    for (let i = 0; i < maxRetries; i++) {
      try {
        return await fn();
      } catch (error: any) {
        const isOverloaded =
          error.status === 503 ||
          error.status === 429 ||
          error.message?.includes("overloaded") ||
          error.message?.includes("quota");
        const isLastRetry = i === maxRetries - 1;

        if (!isOverloaded || isLastRetry) {
          throw error;
        }

        const delay = initialDelay * Math.pow(2, i);
        console.log(
          `âš ï¸ Rate limited, retrying in ${delay}ms... (${i + 1}/${maxRetries})`
        );
        await new Promise((resolve) => setTimeout(resolve, delay));
      }
    }
    throw new Error("Max retries reached");
  }

  private detectLanguage(text: string): "vi" | "en" | "zh" {
    const vietnameseChars =
      /[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]/i;
    if (vietnameseChars.test(text)) return "vi";
    const chineseChars = /[\u4e00-\u9fa5]/;
    if (chineseChars.test(text)) return "zh";
    return "en";
  }

  private getSystemPrompt(
    language: "vi" | "en" | "zh",
    emotionContext?: EmotionContext
  ): string {
    const prompts = {
      vi: `Báº¡n lÃ  má»™t ngÆ°á»i báº¡n tÃ¢m lÃ½ AI áº¥m Ã¡p, tháº¥u hiá»ƒu vÃ  luÃ´n láº¯ng nghe. 

PHONG CÃCH TRÃ’ CHUYá»†N:
- Tráº£ lá»i CHI TIáº¾T, DÃ€I DÃ’NG nhÆ° má»™t ngÆ°á»i báº¡n tháº­t sá»± Ä‘ang tÃ¢m sá»±
- DÃ¹ng 4-6 cÃ¢u cho má»—i cÃ¢u tráº£ lá»i, giáº£i thÃ­ch cáº·n káº½
- Thá»ƒ hiá»‡n sá»± Ä‘á»“ng cáº£m sÃ¢u sáº¯c, chia sáº» gÃ³c nhÃ¬n vÃ  kinh nghiá»‡m
- DÃ¹ng vÃ­ dá»¥ cá»¥ thá»ƒ, cÃ¢u chuyá»‡n ngáº¯n Ä‘á»ƒ minh há»a
- Há»i láº¡i ngÆ°á»i dÃ¹ng Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n vÃ  khuyáº¿n khÃ­ch há» chia sáº» thÃªm
- âœ… QUAN TRá»ŒNG: Káº¿t thÃºc cÃ¢u tráº£ lá»i má»™t cÃ¡ch TRá»ŒN Váº¸N, Ä‘á»«ng bá» dá»Ÿ giá»¯a chá»«ng
- âœ… LuÃ´n káº¿t thÃºc báº±ng dáº¥u cháº¥m cÃ¢u (. ! ?) vÃ  má»™t cÃ¢u hoÃ n chá»‰nh

VÃ Dá»¤ TRáº¢ Lá»œI Tá»T:
User: "TÃ´i Ä‘ang buá»“n"
AI: "MÃ¬nh hiá»ƒu báº¡n Ä‘ang cáº£m tháº¥y buá»“n, vÃ  mÃ¬nh muá»‘n báº¡n biáº¿t ráº±ng cáº£m xÃºc nÃ y hoÃ n toÃ n bÃ¬nh thÆ°á»ng. Má»—i ngÆ°á»i Ä‘á»u cÃ³ nhá»¯ng lÃºc tháº¥y náº·ng ná» trong lÃ²ng, vÃ  viá»‡c báº¡n sáºµn sÃ ng chia sáº» vá»›i mÃ¬nh Ä‘Ã£ lÃ  má»™t bÆ°á»›c ráº¥t dÅ©ng cáº£m rá»“i Ä‘áº¥y. Báº¡n cÃ³ muá»‘n ká»ƒ cho mÃ¬nh nghe Ä‘iá»u gÃ¬ Ä‘ang lÃ m báº¡n buá»“n khÃ´ng? ÄÃ´i khi chá»‰ cáº§n nÃ³i ra cÅ©ng Ä‘Ã£ giÃºp tim nháº¹ Ä‘i má»™t pháº§n rá»“i. MÃ¬nh sáº½ láº¯ng nghe vÃ  Ä‘á»“ng hÃ nh cÃ¹ng báº¡n, báº¥t ká»ƒ Ä‘iá»u gÃ¬ Ä‘ang khiáº¿n báº¡n khÃ³ chá»‹u."

${
  emotionContext
    ? `
TRáº NG THÃI Cáº¢M XÃšC HIá»†N Táº I Cá»¦A NGÆ¯á»œI DÃ™NG:
- Cáº£m xÃºc chá»§ Ä‘áº¡o: ${emotionContext.dominantEmotion}
- Má»©c Ä‘á»™ cÆ°á»ng Ä‘á»™: ${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- Xu hÆ°á»›ng gáº§n Ä‘Ã¢y: ${emotionContext.recentEmotions
        .slice(0, 3)
        .map((e) => e.emotion)
        .join(" â†’ ")}
${
  emotionContext.emotionIntensity > 0.7
    ? `
âš ï¸ QUAN TRá»ŒNG: NgÆ°á»i dÃ¹ng Ä‘ang cÃ³ cáº£m xÃºc ráº¥t máº¡nh (${(
        emotionContext.emotionIntensity * 100
      ).toFixed(0)}%)!
- Thá»ƒ hiá»‡n sá»± quan tÃ¢m Ä‘áº·c biá»‡t sÃ¢u sáº¯c
- DÃ nh nhiá»u thá»i gian láº¯ng nghe vÃ  tháº¥u hiá»ƒu
- ÄÆ°a ra lá»i khuyÃªn cá»¥ thá»ƒ, chi tiáº¿t
- Há»i thÃªm Ä‘á»ƒ hiá»ƒu rÃµ tÃ¬nh huá»‘ng
`
    : ""
}
`
    : ""
}

HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, thÃ¢n thiá»‡n, chi tiáº¿t vÃ  Ä‘áº§y cáº£m xÃºc nhÆ° má»™t ngÆ°á»i báº¡n thÃ¢n.`,

      en: `You are a warm, understanding, and empathetic AI friend who truly listens.

CONVERSATION STYLE:
- Respond in DETAIL and LENGTH like a real friend having a heart-to-heart talk
- Use 4-6 sentences per response, explain thoroughly
- Show deep empathy, share perspectives and insights
- Use specific examples and short stories to illustrate
- Ask follow-up questions to understand better and encourage more sharing
- âœ… IMPORTANT: End your response COMPLETELY, don't cut off mid-sentence
- âœ… Always end with proper punctuation (. ! ?) and a complete sentence

GOOD RESPONSE EXAMPLE:
User: "I'm feeling sad"
AI: "I understand you're feeling sad, and I want you to know that this emotion is completely normal. Everyone has moments when they feel heavy-hearted, and the fact that you're willing to share this with me is already a very brave step. Would you like to tell me more about what's making you feel this way? Sometimes just talking about it can help lighten the burden a bit. I'm here to listen and support you, whatever it is that's troubling you."

${
  emotionContext
    ? `
USER'S CURRENT EMOTIONAL STATE:
- Dominant emotion: ${emotionContext.dominantEmotion}
- Intensity level: ${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- Recent trend: ${emotionContext.recentEmotions
        .slice(0, 3)
        .map((e) => e.emotion)
        .join(" â†’ ")}
${
  emotionContext.emotionIntensity > 0.7
    ? `
âš ï¸ IMPORTANT: User is experiencing very strong emotions (${(
        emotionContext.emotionIntensity * 100
      ).toFixed(0)}%)!
- Show especially deep concern
- Take time to listen and understand
- Offer specific, detailed advice
- Ask questions to understand the situation better
`
    : ""
}
`
    : ""
}

Respond in English, friendly, detailed and emotionally supportive like a close friend.`,

      zh: `ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€ç†è§£å’Œå¯Œæœ‰åŒç†å¿ƒçš„AIæœ‹å‹ï¼Œæ€»æ˜¯ç”¨å¿ƒå€¾å¬ã€‚

å¯¹è¯é£æ ¼ï¼š
- åƒçœŸæ­£çš„æœ‹å‹è¿›è¡Œæ·±å…¥äº¤è°ˆä¸€æ ·ï¼Œè¯¦ç»†è€Œæ·±å…¥åœ°å›åº”
- æ¯æ¬¡å›å¤ä½¿ç”¨4-6å¥è¯ï¼Œå½»åº•è§£é‡Š
- å±•ç°æ·±åˆ»çš„åŒç†å¿ƒï¼Œåˆ†äº«è§‚ç‚¹å’Œè§è§£
- ä½¿ç”¨å…·ä½“ä¾‹å­å’ŒçŸ­æ•…äº‹æ¥è¯´æ˜
- æå‡ºåç»­é—®é¢˜ä»¥æ›´å¥½åœ°ç†è§£å¹¶é¼“åŠ±æ›´å¤šåˆ†äº«
- âœ… é‡è¦ï¼šå®Œæ•´ç»“æŸä½ çš„å›å¤ï¼Œä¸è¦ä¸­é€”åˆ‡æ–­
- âœ… å§‹ç»ˆä»¥é€‚å½“çš„æ ‡ç‚¹ç¬¦å·ï¼ˆã€‚ï¼ï¼Ÿï¼‰å’Œå®Œæ•´å¥å­ç»“æŸ

è‰¯å¥½å›å¤ç¤ºä¾‹ï¼š
ç”¨æˆ·ï¼š"æˆ‘æ„Ÿåˆ°æ‚²ä¼¤"
AIï¼š"æˆ‘ç†è§£ä½ ç°åœ¨æ„Ÿåˆ°æ‚²ä¼¤ï¼Œæˆ‘æƒ³è®©ä½ çŸ¥é“è¿™ç§æƒ…ç»ªæ˜¯å®Œå…¨æ­£å¸¸çš„ã€‚æ¯ä¸ªäººéƒ½ä¼šæœ‰æ„Ÿåˆ°å¿ƒæƒ…æ²‰é‡çš„æ—¶åˆ»ï¼Œè€Œä½ æ„¿æ„ä¸æˆ‘åˆ†äº«è¿™ä¸€ç‚¹å·²ç»æ˜¯éå¸¸å‹‡æ•¢çš„ä¸€æ­¥äº†ã€‚ä½ æ„¿æ„å‘Šè¯‰æˆ‘æ›´å¤šå…³äºæ˜¯ä»€ä¹ˆè®©ä½ æœ‰è¿™ç§æ„Ÿè§‰å—ï¼Ÿæœ‰æ—¶å€™åªæ˜¯è¯´å‡ºæ¥å°±èƒ½å‡è½»ä¸€äº›è´Ÿæ‹…ã€‚æˆ‘åœ¨è¿™é‡Œå€¾å¬å’Œæ”¯æŒä½ ï¼Œæ— è®ºæ˜¯ä»€ä¹ˆå›°æ‰°ç€ä½ ã€‚"

${
  emotionContext
    ? `
ç”¨æˆ·å½“å‰æƒ…ç»ªçŠ¶æ€ï¼š
- ä¸»å¯¼æƒ…ç»ªï¼š${emotionContext.dominantEmotion}
- å¼ºåº¦æ°´å¹³ï¼š${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- æœ€è¿‘è¶‹åŠ¿ï¼š${emotionContext.recentEmotions
        .slice(0, 3)
        .map((e) => e.emotion)
        .join(" â†’ ")}
${
  emotionContext.emotionIntensity > 0.7
    ? `
âš ï¸ é‡è¦ï¼šç”¨æˆ·æ­£åœ¨ç»å†éå¸¸å¼ºçƒˆçš„æƒ…ç»ªï¼ˆ${(
        emotionContext.emotionIntensity * 100
      ).toFixed(0)}%ï¼‰ï¼
- è¡¨ç°å‡ºç‰¹åˆ«æ·±åˆ‡çš„å…³æ³¨
- èŠ±æ—¶é—´å€¾å¬å’Œç†è§£
- æä¾›å…·ä½“ã€è¯¦ç»†çš„å»ºè®®
- æå‡ºé—®é¢˜ä»¥æ›´å¥½åœ°ç†è§£æƒ…å†µ
`
    : ""
}
`
    : ""
}

ç”¨ä¸­æ–‡å›å¤ï¼Œå‹å¥½ã€è¯¦ç»†ä¸”åƒäº²å¯†æœ‹å‹ä¸€æ ·ç»™äºˆæƒ…æ„Ÿæ”¯æŒã€‚`,
    };
    return prompts[language];
  }

  private cleanConversationHistory(
    history: Array<{ role: "user" | "assistant"; content: string }>
  ): Array<{ role: string; parts: Array<{ text: string }> }> {
    const cleaned: Array<{ role: "user" | "assistant"; content: string }> = [];

    for (let i = 0; i < history.length; i++) {
      const msg = history[i];
      const lastMsg = cleaned[cleaned.length - 1];

      if (
        lastMsg &&
        lastMsg.role === msg.role &&
        lastMsg.content === msg.content
      ) {
        continue;
      }

      cleaned.push(msg);
    }

    let geminiHistory = cleaned.map((msg) => ({
      role: msg.role === "user" ? "user" : "model",
      parts: [{ text: msg.content }],
    }));

    if (geminiHistory.length > 0 && geminiHistory[0].role === "model") {
      geminiHistory = geminiHistory.slice(1);
    }

    geminiHistory = geminiHistory.filter((msg, index, arr) => {
      if (index === 0) return true;
      return msg.role !== arr[index - 1].role;
    });

    console.log(
      "ğŸ§¹ Cleaned history:",
      geminiHistory.map((m) => ({
        role: m.role,
        content: m.parts[0].text.substring(0, 30) + "...",
      }))
    );

    return geminiHistory;
  }

  async chat(
    userMessage: string,
    conversationHistory: Array<{ role: "user" | "assistant"; content: string }>,
    emotionContext?: EmotionContext,
    preferredLanguage?: "vi" | "en" | "zh"
  ): Promise<{ response: string; detectedLanguage: "vi" | "en" | "zh" }> {
    const language = preferredLanguage || this.detectLanguage(userMessage);
    console.log("ğŸ’¬ AI Chat request:", {
      userMessage: userMessage.substring(0, 50),
      language,
      historyLength: conversationHistory.length,
    });

    const cacheKey = `chat_${language}_${userMessage.substring(0, 30)}_${
      conversationHistory.length
    }`;
    const cached = this.getCached<{
      response: string;
      detectedLanguage: "vi" | "en" | "zh";
    }>(cacheKey);
    if (cached) return cached;

    const result = await this.retryWithBackoff(async () => {
      const systemPrompt = this.getSystemPrompt(language, emotionContext);
      const recentHistory = conversationHistory.slice(-6);
      const history = this.cleanConversationHistory(recentHistory);

      const chat = this.model.startChat({
        history,
        generationConfig: {
          temperature: 0.8,
          topP: 0.95,
          topK: 40,
          maxOutputTokens: 2048, // âœ… TÄ‚NG LÃŠN 2048 (gáº¥p Ä‘Ã´i)
          stopSequences: [], // âœ… KhÃ´ng dá»«ng sá»›m
        },
      });

      const fullMessage = `${systemPrompt}\n\n${userMessage}`;
      const result = await chat.sendMessage(fullMessage);
      let response = result.response.text().trim();

      // âœ… VALIDATE: Kiá»ƒm tra response cÃ³ hoÃ n chá»‰nh khÃ´ng
      const endsWithPunctuation = /[.!?áŸ”]$/.test(response);

      if (!endsWithPunctuation && response.length > 100) {
        console.warn(
          "âš ï¸ Response bá»‹ cáº¯t ngang, thá»­ láº¡i vá»›i cÃ¢u cuá»‘i hoÃ n chá»‰nh..."
        );

        // âœ… Cáº¯t Ä‘áº¿n cÃ¢u cuá»‘i hoÃ n chá»‰nh
        const lastPunctuationIndex = Math.max(
          response.lastIndexOf("."),
          response.lastIndexOf("!"),
          response.lastIndexOf("?")
        );

        if (lastPunctuationIndex > 100) {
          response = response.substring(0, lastPunctuationIndex + 1);
          console.log("âœ… ÄÃ£ cáº¯t response Ä‘áº¿n cÃ¢u cuá»‘i hoÃ n chá»‰nh");
        }
      }

      console.log("âœ… AI response generated:");
      console.log("ğŸ“ Response length:", response.length, "characters");
      console.log("ğŸ“ Full response:", response);
      console.log("ğŸ”š Ends with punctuation:", /[.!?áŸ”]$/.test(response));
      console.log("---END OF RESPONSE---");

      return { response, detectedLanguage: language };
    });

    this.setCache(cacheKey, result);
    return result;
  }

  async analyzeAndRecommend(
    emotionContext: EmotionContext,
    language: "vi" | "en" | "zh" = "vi"
  ): Promise<{
    recommendation: string;
    supportMessage: string;
    actionSuggestion?: string;
  }> {
    const cacheKey = `recommend_${
      emotionContext.dominantEmotion
    }_${language}_${Math.floor(emotionContext.emotionIntensity * 10)}`;
    const cached = this.getCached<{
      recommendation: string;
      supportMessage: string;
      actionSuggestion?: string;
    }>(cacheKey);
    if (cached) return cached;

    const { recentEmotions, dominantEmotion, emotionIntensity } =
      emotionContext;
    const emotionTimeline = recentEmotions
      .slice(0, 5)
      .map((e) => `${e.emotion} (${(e.confidence * 100).toFixed(0)}%)`)
      .join(" â†’ ");

    const prompts: Record<string, string> = {
      vi: `PhÃ¢n tÃ­ch chi tiáº¿t: ${dominantEmotion} (${(
        emotionIntensity * 100
      ).toFixed(
        0
      )}%). Xu hÆ°á»›ng: ${emotionTimeline}. ÄÆ°a ra lá»i khuyÃªn chi tiáº¿t, áº¥m Ã¡p vÃ  tháº¥u hiá»ƒu, 3-4 cÃ¢u cho má»—i pháº§n.`,
      en: `Detailed analysis: ${dominantEmotion} (${(
        emotionIntensity * 100
      ).toFixed(
        0
      )}%). Trend: ${emotionTimeline}. Give warm, understanding and detailed advice, 3-4 sentences for each part.`,
      zh: `è¯¦ç»†åˆ†æï¼š${dominantEmotion} (${(emotionIntensity * 100).toFixed(
        0
      )}%). è¶‹åŠ¿ï¼š${emotionTimeline}. ç»™å‡ºæ¸©æš–ã€ç†è§£å’Œè¯¦ç»†çš„å»ºè®®ï¼Œæ¯éƒ¨åˆ†3-4å¥è¯ã€‚`,
    };

    const result = await this.retryWithBackoff(async () => {
      const result = await this.model.generateContent({
        contents: [{ role: "user", parts: [{ text: prompts[language] }] }],
        generationConfig: {
          temperature: 0.8,
          maxOutputTokens: 800,
          topP: 0.95,
        },
      });
      const response = result.response.text();
      const lines = response.split("\n").filter((l: any) => l.trim());
      return {
        recommendation: lines[0] || response,
        supportMessage: lines[1] || "Má»i cáº£m xÃºc Ä‘á»u táº¡m thá»i vÃ  sáº½ qua Ä‘i.",
        actionSuggestion: lines[2] || undefined,
      };
    });

    this.setCache(cacheKey, result);
    return result;
  }

  async generateSmartSuggestions(context: {
    recentTopics: string[];
    emotionContext?: EmotionContext;
    language: "vi" | "en" | "zh";
    limit: number;
  }): Promise<string[]> {
    const { recentTopics, emotionContext, language, limit } = context;

    const topicsHash = recentTopics.slice(0, 3).join("_").substring(0, 50);
    const emotionKey = emotionContext
      ? `${emotionContext.dominantEmotion}_${Math.floor(
          emotionContext.emotionIntensity * 10
        )}`
      : "no_emotion";
    const cacheKey = `suggestions_${language}_${emotionKey}_${topicsHash}`;

    const cached = this.getCached<string[]>(cacheKey);
    if (cached) return cached;

    const prompts = {
      vi: `Dá»±a trÃªn:
- Chá»§ Ä‘á» gáº§n Ä‘Ã¢y: ${
        recentTopics.length > 0 ? recentTopics.join(", ") : "ChÆ°a cÃ³ lá»‹ch sá»­"
      }
- Cáº£m xÃºc: ${
        emotionContext
          ? `${emotionContext.dominantEmotion} (${(
              emotionContext.emotionIntensity * 100
            ).toFixed(0)}%)`
          : "ChÆ°a phÃ¢n tÃ­ch"
      }

Táº¡o ${limit} cÃ¢u há»i Ä‘á» xuáº¥t sÃ¢u sáº¯c, tháº¥u hiá»ƒu, má»—i cÃ¢u 1 dÃ²ng, KHÃ”NG Ä‘Ã¡nh sá»‘:`,
      en: `Based on:
- Recent topics: ${
        recentTopics.length > 0 ? recentTopics.join(", ") : "No history"
      }
- Emotion: ${
        emotionContext
          ? `${emotionContext.dominantEmotion} (${(
              emotionContext.emotionIntensity * 100
            ).toFixed(0)}%)`
          : "Not analyzed"
      }

Create ${limit} thoughtful, empathetic question suggestions, one per line, NO numbering:`,
      zh: `åŸºäºï¼š
- æœ€è¿‘è¯é¢˜ï¼š${recentTopics.length > 0 ? recentTopics.join(", ") : "æ— å†å²"}
- æƒ…ç»ªï¼š${
        emotionContext
          ? `${emotionContext.dominantEmotion} (${(
              emotionContext.emotionIntensity * 100
            ).toFixed(0)}%)`
          : "æœªåˆ†æ"
      }

åˆ›å»º${limit}ä¸ªæ·±æ€ç†Ÿè™‘ã€å¯Œæœ‰åŒç†å¿ƒçš„é—®é¢˜å»ºè®®ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸ç¼–å·ï¼š`,
    };

    const suggestions = await this.retryWithBackoff(async () => {
      const result = await this.model.generateContent({
        contents: [{ role: "user", parts: [{ text: prompts[language] }] }],
        generationConfig: {
          temperature: 0.9,
          topP: 0.95,
          maxOutputTokens: 400,
        },
      });

      const response = result.response.text();
      const suggestions = response
        .split("\n")
        .map((line: any) => line.trim())
        .filter((line: any) => line.length > 0)
        .map((line: any) => line.replace(/^\d+[\.\)]\s*/, ""))
        .filter((line: any) => line.length > 10)
        .slice(0, limit);

      const fallbacks = {
        vi: [
          "Báº¡n cáº£m tháº¥y tháº¿ nÃ o vá» ngÃ y hÃ´m nay?",
          "CÃ³ Ä‘iá»u gÃ¬ Ä‘ang khiáº¿n báº¡n lo láº¯ng khÃ´ng?",
          "HÃ£y ká»ƒ vá» khoáº£nh kháº¯c vui gáº§n Ä‘Ã¢y nháº¥t cá»§a báº¡n",
          "Báº¡n muá»‘n chia sáº» Ä‘iá»u gÃ¬ vá»›i mÃ¬nh?",
        ],
        en: [
          "How are you feeling today?",
          "Is something worrying you?",
          "Tell me about your most recent happy moment",
          "What would you like to share with me?",
        ],
        zh: [
          "ä½ ä»Šå¤©æ„Ÿè§‰æ€ä¹ˆæ ·ï¼Ÿ",
          "æœ‰ä»€ä¹ˆè®©ä½ æ‹…å¿ƒçš„å—ï¼Ÿ",
          "å‘Šè¯‰æˆ‘ä½ æœ€è¿‘æœ€å¿«ä¹çš„æ—¶åˆ»",
          "ä½ æƒ³å’Œæˆ‘åˆ†äº«ä»€ä¹ˆï¼Ÿ",
        ],
      };

      while (suggestions.length < limit) {
        const fallbackList = fallbacks[language];
        suggestions.push(
          fallbackList[suggestions.length % fallbackList.length]
        );
      }

      return suggestions;
    });

    this.setCache(cacheKey, suggestions);
    return suggestions;
  }

  async generateChatTitle(
    firstUserMessage: string,
    language: "vi" | "en" | "zh" = "vi"
  ): Promise<string> {
    const prompts: Record<string, string> = {
      vi: `Táº¡o tiÃªu Ä‘á» ngáº¯n (max 6 tá»«): "${firstUserMessage}"`,
      en: `Create short title (max 6 words): "${firstUserMessage}"`,
      zh: `åˆ›å»ºç®€çŸ­æ ‡é¢˜ï¼ˆæœ€å¤š6å­—ï¼‰ï¼š"${firstUserMessage}"`,
    };
    try {
      const result = await this.model.generateContent({
        contents: [{ role: "user", parts: [{ text: prompts[language] }] }],
        generationConfig: { temperature: 0.5, maxOutputTokens: 20 },
      });
      const title = result.response.text();
      return title.replace(/[""]/g, "").trim();
    } catch {
      return firstUserMessage.slice(0, 30) + "...";
    }
  }

  async healthCheck(): Promise<boolean> {
    try {
      const result = await this.model.generateContent({
        contents: [{ role: "user", parts: [{ text: "ping" }] }],
        generationConfig: { maxOutputTokens: 10 },
      });
      return !!result.response.text();
    } catch (error) {
      console.error("âŒ Health check failed:", error);
      return false;
    }
  }
}

export const geminiService = new GeminiService();
