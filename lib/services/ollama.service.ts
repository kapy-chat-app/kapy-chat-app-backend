/* eslint-disable @typescript-eslint/no-explicit-any */
// src/lib/ollama.service.ts - WITH DEBUG LOGS

interface OllamaGenerateResponse {
  model: string;
  created_at: string;
  response: string;
  done: boolean;
  context?: number[];
  total_duration?: number;
  load_duration?: number;
  prompt_eval_count?: number;
}

interface EmotionContext {
  recentEmotions: Array<{
    emotion: string;
    confidence: number;
    timestamp: Date;
  }>;
  dominantEmotion: string;
  emotionIntensity: number;
}

export class OllamaService {
  private ollamaUrl: string;
  private model: string;

  constructor() {
    this.ollamaUrl = process.env.OLLAMA_URL || 'http://127.0.0.1:11434';
    this.model = process.env.OLLAMA_MODEL || 'llama3.2:3b';
    
    console.log('ğŸ¤– Ollama Service initialized:', {
      url: this.ollamaUrl,
      model: this.model
    });
  }

  /**
   * Gá»i Ollama API vá»›i debug logs
   */
  private async callOllama(
    prompt: string,
    systemPrompt?: string,
    temperature: number = 0.7
  ): Promise<string> {
    try {
      const fullPrompt = systemPrompt 
        ? `${systemPrompt}\n\nUser: ${prompt}\n\nAssistant:`
        : prompt;

      console.log('ğŸ“¤ Calling Ollama with prompt:', {
        promptLength: fullPrompt.length,
        temperature,
        model: this.model,
        promptPreview: fullPrompt.substring(0, 200) + '...'
      });

      const requestBody = {
        model: this.model,
        prompt: fullPrompt,
        stream: false,
        options: {
          temperature,
          top_p: 0.9,
          num_predict: 500,
          stop: ['User:', 'Human:']
        }
      };

      console.log('ğŸ“¤ Request body:', JSON.stringify(requestBody, null, 2));

      const response = await fetch(`${this.ollamaUrl}/api/generate`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ Ollama API error:', {
          status: response.status,
          statusText: response.statusText,
          error: errorText
        });
        throw new Error(`Ollama API error: ${response.status} - ${errorText}`);
      }

      const data: OllamaGenerateResponse = await response.json();
      
      console.log('ğŸ“¥ Ollama response:', {
        responseLength: data.response.length,
        responsePreview: data.response.substring(0, 200),
        duration: data.total_duration,
        model: data.model
      });

      return data.response.trim();
    } catch (error) {
      console.error('âŒ Ollama call failed:', error);
      throw error;
    }
  }

  /**
   * PhÃ¡t hiá»‡n ngÃ´n ngá»¯
   */
  private detectLanguage(text: string): 'vi' | 'en' | 'zh' {
    const vietnameseChars = /[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]/i;
    if (vietnameseChars.test(text)) return 'vi';
    
    const chineseChars = /[\u4e00-\u9fa5]/;
    if (chineseChars.test(text)) return 'zh';
    
    return 'en';
  }

  /**
   * Táº¡o system prompt theo ngÃ´n ngá»¯
   */
  private getSystemPrompt(language: 'vi' | 'en' | 'zh', emotionContext?: EmotionContext): string {
    const prompts = {
      vi: `Báº¡n lÃ  má»™t trá»£ lÃ½ tÃ¢m lÃ½ AI thÃ´ng minh vÃ  Ä‘áº§y empathy. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :
- Láº¯ng nghe vÃ  tháº¥u hiá»ƒu cáº£m xÃºc cá»§a ngÆ°á»i dÃ¹ng
- ÄÆ°a ra lá»i khuyÃªn thiáº¿t thá»±c vÃ  tÃ­ch cá»±c
- TrÃ² chuyá»‡n tá»± nhiÃªn, thÃ¢n thiá»‡n nhÆ° má»™t ngÆ°á»i báº¡n
- Tráº£ lá»i ngáº¯n gá»n (2-4 cÃ¢u) trá»« khi Ä‘Æ°á»£c yÃªu cáº§u chi tiáº¿t
${emotionContext ? `
TRáº NG THÃI Cáº¢M XÃšC HIá»†N Táº I:
- Cáº£m xÃºc chá»§ Ä‘áº¡o: ${emotionContext.dominantEmotion}
- CÆ°á»ng Ä‘á»™: ${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- Xu hÆ°á»›ng gáº§n Ä‘Ã¢y: ${emotionContext.recentEmotions.slice(0, 3).map(e => e.emotion).join(' â†’ ')}
${emotionContext.emotionIntensity > 0.7 ? 'âš ï¸ Cáº£m xÃºc Ä‘ang ráº¥t máº¡nh, cáº§n Ä‘áº·c biá»‡t chÃº Ã½!' : ''}
` : ''}
HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.`,

      en: `You are an intelligent and empathetic AI psychology assistant. Your mission:
- Listen and understand the user's emotions
- Provide practical and positive advice
- Chat naturally and friendly like a friend
- Keep responses concise (2-4 sentences) unless asked for details
${emotionContext ? `
CURRENT EMOTIONAL STATE:
- Dominant emotion: ${emotionContext.dominantEmotion}
- Intensity: ${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- Recent trend: ${emotionContext.recentEmotions.slice(0, 3).map(e => e.emotion).join(' â†’ ')}
${emotionContext.emotionIntensity > 0.7 ? 'âš ï¸ Emotions are very intense, special attention needed!' : ''}
` : ''}
Respond in English.`,

      zh: `ä½ æ˜¯ä¸€ä¸ªèªæ˜ä¸”å¯Œæœ‰åŒç†å¿ƒçš„å¿ƒç†AIåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
- å€¾å¬å¹¶ç†è§£ç”¨æˆ·çš„æƒ…ç»ª
- æä¾›å®ç”¨å’Œç§¯æçš„å»ºè®®
- åƒæœ‹å‹ä¸€æ ·è‡ªç„¶å‹å¥½åœ°èŠå¤©
- ä¿æŒç®€æ´å›å¤ï¼ˆ2-4å¥è¯ï¼‰ï¼Œé™¤éè¢«è¦æ±‚è¯¦ç»†è¯´æ˜
${emotionContext ? `
å½“å‰æƒ…ç»ªçŠ¶æ€ï¼š
- ä¸»å¯¼æƒ…ç»ªï¼š${emotionContext.dominantEmotion}
- å¼ºåº¦ï¼š${(emotionContext.emotionIntensity * 100).toFixed(0)}%
- æœ€è¿‘è¶‹åŠ¿ï¼š${emotionContext.recentEmotions.slice(0, 3).map(e => e.emotion).join(' â†’ ')}
${emotionContext.emotionIntensity > 0.7 ? 'âš ï¸ æƒ…ç»ªéå¸¸å¼ºçƒˆï¼Œéœ€è¦ç‰¹åˆ«å…³æ³¨ï¼' : ''}
` : ''}
è¯·ç”¨ä¸­æ–‡å›å¤ã€‚`
    };

    return prompts[language];
  }

  /**
   * Chat vá»›i AI (Ä‘a ngÃ´n ngá»¯) - FIXED VERSION
   */
  async chat(
    userMessage: string,
    conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }>,
    emotionContext?: EmotionContext,
    preferredLanguage?: 'vi' | 'en' | 'zh'
  ): Promise<{ response: string; detectedLanguage: 'vi' | 'en' | 'zh' }> {
    try {
      // Auto-detect language náº¿u khÃ´ng Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh
      const language = preferredLanguage || this.detectLanguage(userMessage);
      
      console.log('ğŸ’¬ Chat request:', {
        userMessage,
        language,
        historyLength: conversationHistory.length,
        hasEmotionContext: !!emotionContext
      });

      const systemPrompt = this.getSystemPrompt(language, emotionContext);

      // âœ… FIX: Build conversation context properly
      const recentHistory = conversationHistory.slice(-6); // Chá»‰ láº¥y 6 tin nháº¯n gáº§n nháº¥t
      
      let conversationText = '';
      if (recentHistory.length > 0) {
        conversationText = recentHistory
          .map(msg => `${msg.role === 'user' ? 'User' : 'Assistant'}: ${msg.content}`)
          .join('\n');
        conversationText += '\n\n';
      }

      // âœ… FIX: Combine properly
      const fullPrompt = `${conversationText}User: ${userMessage}`;

      console.log('ğŸ”§ Built prompt:', {
        systemPromptLength: systemPrompt.length,
        conversationLength: conversationText.length,
        fullPromptLength: fullPrompt.length
      });

      const response = await this.callOllama(fullPrompt, systemPrompt, 0.7);

      console.log('âœ… Chat response generated:', {
        responseLength: response.length,
        language
      });

      return {
        response,
        detectedLanguage: language
      };
    } catch (error) {
      console.error('âŒ Chat error:', error);
      throw error;
    }
  }

  /**
   * PhÃ¢n tÃ­ch cáº£m xÃºc vÃ  Ä‘Æ°a ra gá»£i Ã½
   */
  async analyzeAndRecommend(
    emotionContext: EmotionContext,
    language: 'vi' | 'en' | 'zh' = 'vi'
  ): Promise<{
    recommendation: string;
    supportMessage: string;
    actionSuggestion?: string;
  }> {
    const { recentEmotions, dominantEmotion, emotionIntensity } = emotionContext;

    const emotionTimeline = recentEmotions
      .slice(0, 5)
      .map(e => `${e.emotion} (${(e.confidence * 100).toFixed(0)}%)`)
      .join(' â†’ ');

    const prompts: Record<string, string> = {
      vi: `PhÃ¢n tÃ­ch tráº¡ng thÃ¡i cáº£m xÃºc vÃ  Ä‘Æ°a ra lá»i khuyÃªn:

Cáº¢M XÃšC HIá»†N Táº I: ${dominantEmotion} (cÆ°á»ng Ä‘á»™: ${(emotionIntensity * 100).toFixed(0)}%)
XU HÆ¯á»šNG Gáº¦N ÄÃ‚Y: ${emotionTimeline}
${emotionIntensity > 0.7 ? 'âš ï¸ Cáº£m xÃºc ráº¥t máº¡nh!' : ''}

HÃ£y Ä‘Æ°a ra 3 Ä‘iá»u (má»—i Ä‘iá»u 1-2 cÃ¢u):
1. Nháº­n xÃ©t vá» tráº¡ng thÃ¡i cáº£m xÃºc
2. Lá»i khuyÃªn Ä‘á»ƒ cáº£i thiá»‡n
3. ${emotionIntensity > 0.7 ? 'HÃ nh Ä‘á»™ng cá»¥ thá»ƒ nÃªn lÃ m NGAY' : 'CÃ¡ch duy trÃ¬ tráº¡ng thÃ¡i tá»‘t'}

Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, ngáº¯n gá»n.`,

      en: `Analyze emotional state and provide advice:

CURRENT EMOTION: ${dominantEmotion} (intensity: ${(emotionIntensity * 100).toFixed(0)}%)
RECENT TREND: ${emotionTimeline}
${emotionIntensity > 0.7 ? 'âš ï¸ Very intense emotions!' : ''}

Provide 3 things (1-2 sentences each):
1. Observation about emotional state
2. Advice to improve
3. ${emotionIntensity > 0.7 ? 'Specific action to take NOW' : 'How to maintain good state'}

Respond in English, concisely.`,

      zh: `åˆ†ææƒ…ç»ªçŠ¶æ€å¹¶æä¾›å»ºè®®ï¼š

å½“å‰æƒ…ç»ªï¼š${dominantEmotion}ï¼ˆå¼ºåº¦ï¼š${(emotionIntensity * 100).toFixed(0)}%ï¼‰
æœ€è¿‘è¶‹åŠ¿ï¼š${emotionTimeline}
${emotionIntensity > 0.7 ? 'âš ï¸ æƒ…ç»ªéå¸¸å¼ºçƒˆï¼' : ''}

è¯·æä¾›3ç‚¹ï¼ˆæ¯ç‚¹1-2å¥è¯ï¼‰ï¼š
1. å¯¹æƒ…ç»ªçŠ¶æ€çš„è§‚å¯Ÿ
2. æ”¹å–„å»ºè®®
3. ${emotionIntensity > 0.7 ? 'åº”è¯¥ç«‹å³é‡‡å–çš„å…·ä½“è¡ŒåŠ¨' : 'å¦‚ä½•ä¿æŒè‰¯å¥½çŠ¶æ€'}

ç”¨ä¸­æ–‡ç®€æ´å›å¤ã€‚`
    };

    const response = await this.callOllama(prompts[language], '', 0.7);
    
    // Parse response
    const lines = response.split('\n').filter(l => l.trim());
    
    return {
      recommendation: lines[0] || response,
      supportMessage: lines[1] || "Remember, all emotions are temporary.",
      actionSuggestion: lines[2] || undefined
    };
  }

  /**
   * Táº¡o tiÃªu Ä‘á» tá»± Ä‘á»™ng
   */
  async generateChatTitle(firstUserMessage: string, language: 'vi' | 'en' | 'zh' = 'vi'): Promise<string> {
    const prompts: Record<string, string> = {
      vi: `Táº¡o má»™t tiÃªu Ä‘á» ngáº¯n gá»n (tá»‘i Ä‘a 6 tá»«) cho cuá»™c trÃ² chuyá»‡n báº¯t Ä‘áº§u vá»›i: "${firstUserMessage}"\n\nChá»‰ tráº£ vá» tiÃªu Ä‘á», khÃ´ng giáº£i thÃ­ch.`,
      en: `Create a concise title (max 6 words) for a conversation starting with: "${firstUserMessage}"\n\nReturn only the title, no explanation.`,
      zh: `ä¸ºå¼€å§‹äº"${firstUserMessage}"çš„å¯¹è¯åˆ›å»ºä¸€ä¸ªç®€æ´çš„æ ‡é¢˜ï¼ˆæœ€å¤š6ä¸ªå­—ï¼‰\n\nåªè¿”å›æ ‡é¢˜ï¼Œä¸è¦è§£é‡Šã€‚`
    };

    try {
      const title = await this.callOllama(prompts[language], '', 0.5);
      return title.replace(/[""]/g, '').trim();
    } catch {
      return firstUserMessage.slice(0, 30) + '...';
    }
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<boolean> {
    try {
      const response = await fetch(`${this.ollamaUrl}/api/tags`, {
        signal: AbortSignal.timeout(5000)
      });
      return response.ok;
    } catch {
      return false;
    }
  }
}

// Singleton instance
export const ollamaService = new OllamaService();